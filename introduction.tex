\chapter*{Введение}
\addcontentsline{toc}{chapter}{Введение}
Данный дипломный проект рассматривает приложения распределенного вычисления бигармонического уравнения и анализ производительности алгоритма. Вычисление проводились методом Монте-Карло, а выполнен он с помощью технологии MPI (Message Passing Interface). Одной из целей работ является сравнение эффективности приложений распределенного и последовательного вычисления, а также общая оценка эффективности алгоритма.

Официальной датой рождения метода Монте-Карло принято считать 1949 год, когда была опубликована статья С. Улама и Н. Метрополиса \cite{int:fist} . Сам термин был предложен еще во время Второй мировой войны выдающимися учеными XX века математиком Дж. фон Нейманом и физиком Энрико Ферми в Лос-Аламосе (США) в процессе работ по ядерной тематике. Хотя методы Монте-Карло были известны и до 40-х годов, интенсивное развитие статистическое моделирование получило несколько позже в связи с появлением компьютеров, что позволило проводить вычисления больших объемов. С другой стороны, более широкое распространение получает статистическое описание тех или иных сложных физических процессов в связи с чем методы Монте-Карло все более активно используются во многих научных областях (теория переноса, теория массового обслуживания, теория надежности, статистическая физика и др.).

Одна из схем решения краевых задач методом Монте-Карло заключается в сведении исходной дифференциальной задачи к некоторым конечно-разностным уравнениям. Для решение данных уравнений используется "Алгоритм блуждания по решетке" и "Алгоритм блуждания по сферам". Основным недостатком данных алгоритмов является большой объем независимых друг от друга случайных вычислений. Данная независимость вычислений позволяет распараллелить их. Для распараллеливания данного действия и применяется MPI. 

Message Passing Interface (MPI, интерфейс передачи сообщений) — программный интерфейс (API)\footnote{см. сокращение} для передачи информации, который позволяет обмениваться сообщениями между процессами, выполняющими одну задачу. Разработан Уильямом Гроуппом, Эвином Ласком и другими.

MPI является наиболее распространённым стандартом интерфейса обмена данными в параллельном программировании. Существуют его реализации для большого числа компьютерных платформ. MPI используется при разработке программ для кластеров и суперкомпьютеров. Основным средством коммуникации между процессами в MPI является передача сообщений друг другу. Стандартизацией MPI занимается MPI Forum. В стандарте MPI описан интерфейс передачи сообщений, который должен поддерживаться как на платформе, так и в приложениях пользователя. В настоящее время существует большое количество бесплатных и коммерческих реализаций MPI. Существуют реализации для языков Фортран 77/90, Java, Си и Си++.

В первую очередь MPI ориентирован на системы с распределенной памятью, то есть когда затраты на передачу данных велики, в то время как OpenMP\footnote{http://openmp.org/wp/} ориентирован на системы с общей памятью (многоядерные с общим кэшем). Обе технологии могут использоваться совместно, дабы оптимально использовать в кластере многоядерные системы. Более подробно об этом \cite{mpi:offsite}













